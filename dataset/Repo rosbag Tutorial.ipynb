{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended only as an example of how to read a bag file.\n",
    "\n",
    "In order to run this notebook you will need ROS [Kinetic Kame](http://wiki.ros.org/kinetic) and Python 2.7.\n",
    "\n",
    "The whole dataset can be downloaded (6.6 GB) [here](https://drive.switch.ch/index.php/s/1Q0zN0XDzyRxug4); in this example we will use only `1.bag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import rosbag\n",
    "import tqdm as tqdm\n",
    "\n",
    "from direct_controller import Controller\n",
    "from global_parameters import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary is present in `global_parameters.py` but reported here for ease of reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_file_path_example = {\n",
    "    \"1\": \"../bagfiles/train/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read the information from a bag file and save it as dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../bagfiles/train/1.bag\n"
     ]
    }
   ],
   "source": [
    "file_name = \"1.bag\"\n",
    "path = bag_file_path_example[file_name[:-4]]\n",
    "print(path+file_name)\n",
    "bag = rosbag.Bag(path + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `bag` loaded we can start to extract information from the topics. In the script `dataset_generator.py` we would call `get_bag_data_pandas()` and pass the `bag` variable and the model type. Here we will on show how the function works. \n",
    "\n",
    "---\n",
    "We will create a single dataset for the model of approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_id = [] # list of ids\n",
    "bt_v = [] # list of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we extract the optitrack twist information\n",
    "for topic, beboptw, t in bag.read_messages(topics=['/bebop/mocap_odom']): # for each message(beboptw) in the topic\n",
    "    secs = t.secs \n",
    "    nsecs = t.nsecs\n",
    "    bt_id.append(time_conversion_to_nano(secs, nsecs)) # time.secs and time.nsecs are summed (as nano sec) \n",
    "                                                       # and used as id.\n",
    "    twist_dict = (lambda x: {'t_x': x.x,\n",
    "                             't_y': x.y})(beboptw.twist.twist.linear) # We extract only the information that \n",
    "                                                                      # we are interested in\n",
    "    bt_v.append(twist_dict) # we append it to the value list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bebop_twist_df = pd.DataFrame(data=bt_v, index=bt_id, columns=bt_v[0].keys()) # with the bt_id and bt_v lists we\n",
    "                                                                              # create a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat this process for all the topics that we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from \"/bebop/odom\"\n",
    "odom_id = []\n",
    "odom_v = []\n",
    "for topic, msg, t in bag.read_messages(topics=['/bebop/odom']):\n",
    "    vel = msg.twist\n",
    "    results = [vel.twist.linear.x, vel.twist.linear.y]\n",
    "    secs = t.secs\n",
    "    nsecs = t.nsecs\n",
    "    odom_id.append(time_conversion_to_nano(secs, nsecs))\n",
    "    vel_dict = (lambda x: {'x_vel': x[0],\n",
    "                           'y_vel': x[1]})(results)\n",
    "    odom_v.append(vel_dict)\n",
    "odom_df = pd.DataFrame(data=odom_v, index=odom_id, columns=odom_v[0].keys())\n",
    "\n",
    "# extract data from \"/bebop/image_raw/compressed\"\n",
    "c_id = []\n",
    "c_v = []\n",
    "for topic, image_frame, t in bag.read_messages(topics=['/bebop/image_raw/compressed']):\n",
    "    secs = t.secs\n",
    "    nsecs = t.nsecs\n",
    "    c_id.append(time_conversion_to_nano(secs, nsecs))\n",
    "    img = jpeg2np(image_frame.data, (image_width, image_height))\n",
    "    camera_frame = (lambda x: {'vid': x})(img)\n",
    "    c_v.append(camera_frame)\n",
    "camera_df = pd.DataFrame(data=c_v, index=c_id, columns=c_v[0].keys())\n",
    "\n",
    "# extract data from \"/optitrack/head\"\n",
    "h_id = []\n",
    "h_v = []\n",
    "for topic, hat, t in bag.read_messages(topics=['/optitrack/head']):\n",
    "    secs = t.secs\n",
    "    nsecs = t.nsecs\n",
    "    h_id.append(time_conversion_to_nano(secs, nsecs))\n",
    "    pos_rot_dict = (lambda x, y: {'h_pos_x': x.x,\n",
    "                                  'h_pos_y': x.y,\n",
    "                                  'h_pos_z': x.z,\n",
    "                                  'h_rot_w': y.w,\n",
    "                                  'h_rot_x': y.x,\n",
    "                                  'h_rot_y': y.y,\n",
    "                                  'h_rot_z': y.z})(hat.pose.position, hat.pose.orientation)\n",
    "    h_v.append(pos_rot_dict)\n",
    "head_df = pd.DataFrame(data=h_v, index=h_id, columns=h_v[0].keys())\n",
    "\n",
    "# extract data from \"/optitrack/bebop\"\n",
    "b_id = []\n",
    "b_v = []\n",
    "for topic, bebop, t in bag.read_messages(topics=['/optitrack/bebop']):\n",
    "    secs = t.secs\n",
    "    nsecs = t.nsecs\n",
    "    b_id.append(time_conversion_to_nano(secs, nsecs))\n",
    "    pos_rot_dict = (lambda x, y: {'b_pos_x': x.x,\n",
    "                                  'b_pos_y': x.y,\n",
    "                                  'b_pos_z': x.z,\n",
    "                                  'b_rot_w': y.w,\n",
    "                                  'b_rot_x': y.x,\n",
    "                                  'b_rot_y': y.y,\n",
    "                                  'b_rot_z': y.z})(bebop.pose.position, bebop.pose.orientation)\n",
    "    b_v.append(pos_rot_dict)\n",
    "bebop_df = pd.DataFrame(data=b_v, index=b_id, columns=b_v[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we close the bag file and create a dictionary with all the extracted dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag.close()\n",
    "resulting_dictionary = {'head_df': head_df, 'bebop_df': bebop_df, 'odom_df': odom_df,\\\n",
    "                        'camera_df': camera_df, 'bebop_twist_df': bebop_twist_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the repository script we return this dictionary and use it as a parameter for another method call: `processing()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1524134860684665704 1524134860685877347 1524134860686668596 ...\n",
      " 1524134972471268497 1524134972498969542 1524134972531661089]\n"
     ]
    }
   ],
   "source": [
    "f = file_name\n",
    "data_id = f\n",
    "# we select the ids of each dataframe, NB id == timestamp in nanosec\n",
    "camera_t = resulting_dictionary[\"camera_df\"].index.values\n",
    "bebop_t = resulting_dictionary[\"bebop_df\"].index.values\n",
    "head_t = resulting_dictionary[\"head_df\"].index.values\n",
    "odom_t = resulting_dictionary[\"odom_df\"].index.values\n",
    "bebop_twist_t = resulting_dictionary[\"bebop_twist_df\"].index.values\n",
    "print(camera_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As explained in the README, each bag file is \"cut\" to avoid useless sections.\n",
    "bag_end_cut_example = {\n",
    "    \"1\": 3150\n",
    "}\n",
    "bag_start_cut_example = {\n",
    "    \"1\": 0\n",
    "}\n",
    "max_ = bag_end_cut_example[f[:-4]]\n",
    "min_ = bag_start_cut_example[f[:-4]]\n",
    "data_vec = []\n",
    "\n",
    "# We initialize the hand-programmed controller\n",
    "d_ctrl = Controller()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we iterate on the dataframes rows  in order to:\n",
    "* synchronize the rows\n",
    "* compute new information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing data 1.bag: 100%|██████████| 3150/3150 [00:12<00:00, 247.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(min_, max_), desc=\"processing data \" + str(data_id)):\n",
    "    \n",
    "    # we find the nearest datapoint to the i-th datapoint of the camera feed\n",
    "    b_id = find_nearest(bebop_t, camera_t[i])\n",
    "    h_id = find_nearest(head_t, camera_t[i])\n",
    "    odom_id = find_nearest(odom_t, camera_t[i])\n",
    "    \n",
    "    # with the new ids we extract the nearest rows in each dataframe\n",
    "    head_pose = resulting_dictionary[\"head_df\"].iloc[h_id]\n",
    "    bebop_pose = resulting_dictionary[\"bebop_df\"].iloc[b_id]\n",
    "    odom_info = resulting_dictionary[\"odom_df\"].iloc[odom_id]\n",
    "    \n",
    "    # we also extract the video feed\n",
    "    img = resulting_dictionary[\"camera_df\"].iloc[i].values[0]\n",
    "    \n",
    "    # we change the frame of reference of the user's head's pose from World to Drone (bebop). the result is a 4x4 \n",
    "    # rototranslation matrix\n",
    "    b_t_h = change_frame_reference(bebop_pose, head_pose)\n",
    "    \n",
    "    # we extract the visual odometry velocities\n",
    "    vel_x = odom_info.x_vel\n",
    "    vel_y = odom_info.y_vel\n",
    "\n",
    "    # we extract the yaw angle of the drone and user's head\n",
    "    quaternion_bebop = bebop_pose[['b_rot_x', 'b_rot_y', 'b_rot_z', 'b_rot_w']].values\n",
    "    _, _, bebop_yaw = quat_to_eul(quaternion_bebop)\n",
    "    quaternion_head = head_pose[['h_rot_x', 'h_rot_y', 'h_rot_z', 'h_rot_w']].values\n",
    "    _, _, head_yaw = quat_to_eul(quaternion_head)\n",
    "\n",
    "    # we compute the relative yaw of the user's head wrt the drone\n",
    "    relative_yaw = (head_yaw - bebop_yaw - np.pi)\n",
    "    if relative_yaw < -np.pi:\n",
    "        relative_yaw += 2 * np.pi\n",
    "        \n",
    "    # we extract the user (target) position vector from the matrix \n",
    "    target_position = b_t_h[:-1, -1:].T[0]\n",
    "    target = (target_position[0], target_position[1], target_position[2], relative_yaw)\n",
    "    \n",
    "    # we append the selected variables to a list\n",
    "    data_vec.append((img, target, np.asarray([vel_x, vel_y])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data_vec` is returned and passed to another method in order to save it as pickle. Below we directly save it as `example.pickle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we would use \n",
    "# f_pickle_ = f[:-4] + \".pickle\"\n",
    "f_pickle_ = \"example.pickle\"\n",
    "df = pd.DataFrame(list(data_vec))\n",
    "df.to_pickle(\"../dataset/\" + f_pickle_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
